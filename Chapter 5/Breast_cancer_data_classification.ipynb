{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as ds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0         17.990         10.38          122.80     1001.0          0.11840   \n",
      "1         20.570         17.77          132.90     1326.0          0.08474   \n",
      "2         19.690         21.25          130.00     1203.0          0.10960   \n",
      "3         11.420         20.38           77.58      386.1          0.14250   \n",
      "4         20.290         14.34          135.10     1297.0          0.10030   \n",
      "5         12.450         15.70           82.57      477.1          0.12780   \n",
      "6         18.250         19.98          119.60     1040.0          0.09463   \n",
      "7         13.710         20.83           90.20      577.9          0.11890   \n",
      "8         13.000         21.82           87.50      519.8          0.12730   \n",
      "9         12.460         24.04           83.97      475.9          0.11860   \n",
      "10        16.020         23.24          102.70      797.8          0.08206   \n",
      "11        15.780         17.89          103.60      781.0          0.09710   \n",
      "12        19.170         24.80          132.40     1123.0          0.09740   \n",
      "13        15.850         23.95          103.70      782.7          0.08401   \n",
      "14        13.730         22.61           93.60      578.3          0.11310   \n",
      "15        14.540         27.54           96.73      658.8          0.11390   \n",
      "16        14.680         20.13           94.74      684.5          0.09867   \n",
      "17        16.130         20.68          108.10      798.8          0.11700   \n",
      "18        19.810         22.15          130.00     1260.0          0.09831   \n",
      "19        13.540         14.36           87.46      566.3          0.09779   \n",
      "20        13.080         15.71           85.63      520.0          0.10750   \n",
      "21         9.504         12.44           60.34      273.9          0.10240   \n",
      "22        15.340         14.26          102.50      704.4          0.10730   \n",
      "23        21.160         23.04          137.20     1404.0          0.09428   \n",
      "24        16.650         21.38          110.00      904.6          0.11210   \n",
      "25        17.140         16.40          116.00      912.7          0.11860   \n",
      "26        14.580         21.53           97.41      644.8          0.10540   \n",
      "27        18.610         20.25          122.10     1094.0          0.09440   \n",
      "28        15.300         25.27          102.40      732.4          0.10820   \n",
      "29        17.570         15.05          115.00      955.1          0.09847   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "539        7.691         25.44           48.34      170.4          0.08668   \n",
      "540       11.540         14.44           74.65      402.9          0.09984   \n",
      "541       14.470         24.99           95.81      656.4          0.08837   \n",
      "542       14.740         25.42           94.70      668.6          0.08275   \n",
      "543       13.210         28.06           84.88      538.4          0.08671   \n",
      "544       13.870         20.70           89.77      584.8          0.09578   \n",
      "545       13.620         23.23           87.19      573.2          0.09246   \n",
      "546       10.320         16.35           65.31      324.9          0.09434   \n",
      "547       10.260         16.58           65.85      320.8          0.08877   \n",
      "548        9.683         19.34           61.05      285.7          0.08491   \n",
      "549       10.820         24.21           68.89      361.6          0.08192   \n",
      "550       10.860         21.48           68.51      360.5          0.07431   \n",
      "551       11.130         22.44           71.49      378.4          0.09566   \n",
      "552       12.770         29.43           81.35      507.9          0.08276   \n",
      "553        9.333         21.94           59.01      264.0          0.09240   \n",
      "554       12.880         28.92           82.50      514.3          0.08123   \n",
      "555       10.290         27.61           65.67      321.4          0.09030   \n",
      "556       10.160         19.59           64.73      311.7          0.10030   \n",
      "557        9.423         27.88           59.26      271.3          0.08123   \n",
      "558       14.590         22.68           96.39      657.1          0.08473   \n",
      "559       11.510         23.93           74.52      403.5          0.09261   \n",
      "560       14.050         27.15           91.38      600.4          0.09929   \n",
      "561       11.200         29.37           70.67      386.0          0.07449   \n",
      "562       15.220         30.62          103.40      716.9          0.10480   \n",
      "563       20.920         25.09          143.00     1347.0          0.10990   \n",
      "564       21.560         22.39          142.00     1479.0          0.11100   \n",
      "565       20.130         28.25          131.20     1261.0          0.09780   \n",
      "566       16.600         28.08          108.30      858.1          0.08455   \n",
      "567       20.600         29.33          140.10     1265.0          0.11780   \n",
      "568        7.760         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760        0.300100             0.147100         0.2419   \n",
      "1             0.07864        0.086900             0.070170         0.1812   \n",
      "2             0.15990        0.197400             0.127900         0.2069   \n",
      "3             0.28390        0.241400             0.105200         0.2597   \n",
      "4             0.13280        0.198000             0.104300         0.1809   \n",
      "5             0.17000        0.157800             0.080890         0.2087   \n",
      "6             0.10900        0.112700             0.074000         0.1794   \n",
      "7             0.16450        0.093660             0.059850         0.2196   \n",
      "8             0.19320        0.185900             0.093530         0.2350   \n",
      "9             0.23960        0.227300             0.085430         0.2030   \n",
      "10            0.06669        0.032990             0.033230         0.1528   \n",
      "11            0.12920        0.099540             0.066060         0.1842   \n",
      "12            0.24580        0.206500             0.111800         0.2397   \n",
      "13            0.10020        0.099380             0.053640         0.1847   \n",
      "14            0.22930        0.212800             0.080250         0.2069   \n",
      "15            0.15950        0.163900             0.073640         0.2303   \n",
      "16            0.07200        0.073950             0.052590         0.1586   \n",
      "17            0.20220        0.172200             0.102800         0.2164   \n",
      "18            0.10270        0.147900             0.094980         0.1582   \n",
      "19            0.08129        0.066640             0.047810         0.1885   \n",
      "20            0.12700        0.045680             0.031100         0.1967   \n",
      "21            0.06492        0.029560             0.020760         0.1815   \n",
      "22            0.21350        0.207700             0.097560         0.2521   \n",
      "23            0.10220        0.109700             0.086320         0.1769   \n",
      "24            0.14570        0.152500             0.091700         0.1995   \n",
      "25            0.22760        0.222900             0.140100         0.3040   \n",
      "26            0.18680        0.142500             0.087830         0.2252   \n",
      "27            0.10660        0.149000             0.077310         0.1697   \n",
      "28            0.16970        0.168300             0.087510         0.1926   \n",
      "29            0.11570        0.098750             0.079530         0.1739   \n",
      "..                ...             ...                  ...            ...   \n",
      "539           0.11990        0.092520             0.013640         0.2037   \n",
      "540           0.11200        0.067370             0.025940         0.1818   \n",
      "541           0.12300        0.100900             0.038900         0.1872   \n",
      "542           0.07214        0.041050             0.030270         0.1840   \n",
      "543           0.06877        0.029870             0.032750         0.1628   \n",
      "544           0.10180        0.036880             0.023690         0.1620   \n",
      "545           0.06747        0.029740             0.024430         0.1664   \n",
      "546           0.04994        0.010120             0.005495         0.1885   \n",
      "547           0.08066        0.043580             0.024380         0.1669   \n",
      "548           0.05030        0.023370             0.009615         0.1580   \n",
      "549           0.06602        0.015480             0.008160         0.1976   \n",
      "550           0.04227        0.000000             0.000000         0.1661   \n",
      "551           0.08194        0.048240             0.022570         0.2030   \n",
      "552           0.04234        0.019970             0.014990         0.1539   \n",
      "553           0.05605        0.039960             0.012820         0.1692   \n",
      "554           0.05824        0.061950             0.023430         0.1566   \n",
      "555           0.07658        0.059990             0.027380         0.1593   \n",
      "556           0.07504        0.005025             0.011160         0.1791   \n",
      "557           0.04971        0.000000             0.000000         0.1742   \n",
      "558           0.13300        0.102900             0.037360         0.1454   \n",
      "559           0.10210        0.111200             0.041050         0.1388   \n",
      "560           0.11260        0.044620             0.043040         0.1537   \n",
      "561           0.03558        0.000000             0.000000         0.1060   \n",
      "562           0.20870        0.255000             0.094290         0.2128   \n",
      "563           0.22360        0.317400             0.147400         0.2149   \n",
      "564           0.11590        0.243900             0.138900         0.1726   \n",
      "565           0.10340        0.144000             0.097910         0.1752   \n",
      "566           0.10230        0.092510             0.053020         0.1590   \n",
      "567           0.27700        0.351400             0.152000         0.2397   \n",
      "568           0.04362        0.000000             0.000000         0.1587   \n",
      "\n",
      "     mean fractal dimension     ...       worst texture  worst perimeter  \\\n",
      "0                   0.07871     ...               17.33           184.60   \n",
      "1                   0.05667     ...               23.41           158.80   \n",
      "2                   0.05999     ...               25.53           152.50   \n",
      "3                   0.09744     ...               26.50            98.87   \n",
      "4                   0.05883     ...               16.67           152.20   \n",
      "5                   0.07613     ...               23.75           103.40   \n",
      "6                   0.05742     ...               27.66           153.20   \n",
      "7                   0.07451     ...               28.14           110.60   \n",
      "8                   0.07389     ...               30.73           106.20   \n",
      "9                   0.08243     ...               40.68            97.65   \n",
      "10                  0.05697     ...               33.88           123.80   \n",
      "11                  0.06082     ...               27.28           136.50   \n",
      "12                  0.07800     ...               29.94           151.70   \n",
      "13                  0.05338     ...               27.66           112.00   \n",
      "14                  0.07682     ...               32.01           108.80   \n",
      "15                  0.07077     ...               37.13           124.10   \n",
      "16                  0.05922     ...               30.88           123.40   \n",
      "17                  0.07356     ...               31.48           136.80   \n",
      "18                  0.05395     ...               30.88           186.80   \n",
      "19                  0.05766     ...               19.26            99.70   \n",
      "20                  0.06811     ...               20.49            96.09   \n",
      "21                  0.06905     ...               15.66            65.13   \n",
      "22                  0.07032     ...               19.08           125.10   \n",
      "23                  0.05278     ...               35.59           188.00   \n",
      "24                  0.06330     ...               31.56           177.00   \n",
      "25                  0.07413     ...               21.40           152.40   \n",
      "26                  0.06924     ...               33.21           122.40   \n",
      "27                  0.05699     ...               27.26           139.90   \n",
      "28                  0.06540     ...               36.71           149.30   \n",
      "29                  0.06149     ...               19.52           134.90   \n",
      "..                      ...     ...                 ...              ...   \n",
      "539                 0.07751     ...               31.89            54.49   \n",
      "540                 0.06782     ...               19.68            78.78   \n",
      "541                 0.06341     ...               31.73           113.50   \n",
      "542                 0.05680     ...               32.29           107.40   \n",
      "543                 0.05781     ...               37.17            92.48   \n",
      "544                 0.06688     ...               24.75            99.17   \n",
      "545                 0.05801     ...               29.09            97.58   \n",
      "546                 0.06201     ...               21.77            71.12   \n",
      "547                 0.06714     ...               22.04            71.08   \n",
      "548                 0.06235     ...               25.59            69.10   \n",
      "549                 0.06328     ...               31.45            83.90   \n",
      "550                 0.05948     ...               24.77            74.08   \n",
      "551                 0.06552     ...               28.26            77.80   \n",
      "552                 0.05637     ...               36.00            88.10   \n",
      "553                 0.06576     ...               25.05            62.86   \n",
      "554                 0.05708     ...               35.74            88.84   \n",
      "555                 0.06127     ...               34.91            69.57   \n",
      "556                 0.06331     ...               22.88            67.88   \n",
      "557                 0.06059     ...               34.24            66.50   \n",
      "558                 0.06147     ...               27.27           105.90   \n",
      "559                 0.06570     ...               37.16            82.28   \n",
      "560                 0.06171     ...               33.17           100.20   \n",
      "561                 0.05502     ...               38.30            75.19   \n",
      "562                 0.07152     ...               42.79           128.70   \n",
      "563                 0.06879     ...               29.41           179.10   \n",
      "564                 0.05623     ...               26.40           166.10   \n",
      "565                 0.05533     ...               38.25           155.00   \n",
      "566                 0.05648     ...               34.12           126.70   \n",
      "567                 0.07016     ...               39.42           184.60   \n",
      "568                 0.05884     ...               30.37            59.16   \n",
      "\n",
      "     worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0        2019.0           0.16220            0.66560          0.71190   \n",
      "1        1956.0           0.12380            0.18660          0.24160   \n",
      "2        1709.0           0.14440            0.42450          0.45040   \n",
      "3         567.7           0.20980            0.86630          0.68690   \n",
      "4        1575.0           0.13740            0.20500          0.40000   \n",
      "5         741.6           0.17910            0.52490          0.53550   \n",
      "6        1606.0           0.14420            0.25760          0.37840   \n",
      "7         897.0           0.16540            0.36820          0.26780   \n",
      "8         739.3           0.17030            0.54010          0.53900   \n",
      "9         711.4           0.18530            1.05800          1.10500   \n",
      "10       1150.0           0.11810            0.15510          0.14590   \n",
      "11       1299.0           0.13960            0.56090          0.39650   \n",
      "12       1332.0           0.10370            0.39030          0.36390   \n",
      "13        876.5           0.11310            0.19240          0.23220   \n",
      "14        697.7           0.16510            0.77250          0.69430   \n",
      "15        943.2           0.16780            0.65770          0.70260   \n",
      "16       1138.0           0.14640            0.18710          0.29140   \n",
      "17       1315.0           0.17890            0.42330          0.47840   \n",
      "18       2398.0           0.15120            0.31500          0.53720   \n",
      "19        711.2           0.14400            0.17730          0.23900   \n",
      "20        630.5           0.13120            0.27760          0.18900   \n",
      "21        314.9           0.13240            0.11480          0.08867   \n",
      "22        980.9           0.13900            0.59540          0.63050   \n",
      "23       2615.0           0.14010            0.26000          0.31550   \n",
      "24       2215.0           0.18050            0.35780          0.46950   \n",
      "25       1461.0           0.15450            0.39490          0.38530   \n",
      "26        896.9           0.15250            0.66430          0.55390   \n",
      "27       1403.0           0.13380            0.21170          0.34460   \n",
      "28       1269.0           0.16410            0.61100          0.63350   \n",
      "29       1227.0           0.12550            0.28120          0.24890   \n",
      "..          ...               ...                ...              ...   \n",
      "539       223.6           0.15960            0.30640          0.33930   \n",
      "540       457.8           0.13450            0.21180          0.17970   \n",
      "541       808.9           0.13400            0.42020          0.40400   \n",
      "542       826.4           0.10600            0.13760          0.16110   \n",
      "543       629.6           0.10720            0.13810          0.10620   \n",
      "544       688.6           0.12640            0.20370          0.13770   \n",
      "545       729.8           0.12160            0.15170          0.10490   \n",
      "546       384.9           0.12850            0.08842          0.04384   \n",
      "547       357.4           0.14610            0.22460          0.17830   \n",
      "548       364.2           0.11990            0.09546          0.09350   \n",
      "549       505.6           0.12040            0.16330          0.06194   \n",
      "550       412.3           0.10010            0.07348          0.00000   \n",
      "551       436.6           0.10870            0.17820          0.15640   \n",
      "552       594.7           0.12340            0.10640          0.08653   \n",
      "553       295.8           0.11030            0.08298          0.07993   \n",
      "554       595.7           0.12270            0.16200          0.24390   \n",
      "555       357.6           0.13840            0.17100          0.20000   \n",
      "556       347.3           0.12650            0.12000          0.01005   \n",
      "557       330.6           0.10730            0.07158          0.00000   \n",
      "558       733.5           0.10260            0.31710          0.36620   \n",
      "559       474.2           0.12980            0.25170          0.36300   \n",
      "560       706.7           0.12410            0.22640          0.13260   \n",
      "561       439.6           0.09267            0.05494          0.00000   \n",
      "562       915.0           0.14170            0.79170          1.17000   \n",
      "563      1819.0           0.14070            0.41860          0.65990   \n",
      "564      2027.0           0.14100            0.21130          0.41070   \n",
      "565      1731.0           0.11660            0.19220          0.32150   \n",
      "566      1124.0           0.11390            0.30940          0.34030   \n",
      "567      1821.0           0.16500            0.86810          0.93870   \n",
      "568       268.6           0.08996            0.06444          0.00000   \n",
      "\n",
      "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
      "0                 0.26540          0.4601                  0.11890   \n",
      "1                 0.18600          0.2750                  0.08902   \n",
      "2                 0.24300          0.3613                  0.08758   \n",
      "3                 0.25750          0.6638                  0.17300   \n",
      "4                 0.16250          0.2364                  0.07678   \n",
      "5                 0.17410          0.3985                  0.12440   \n",
      "6                 0.19320          0.3063                  0.08368   \n",
      "7                 0.15560          0.3196                  0.11510   \n",
      "8                 0.20600          0.4378                  0.10720   \n",
      "9                 0.22100          0.4366                  0.20750   \n",
      "10                0.09975          0.2948                  0.08452   \n",
      "11                0.18100          0.3792                  0.10480   \n",
      "12                0.17670          0.3176                  0.10230   \n",
      "13                0.11190          0.2809                  0.06287   \n",
      "14                0.22080          0.3596                  0.14310   \n",
      "15                0.17120          0.4218                  0.13410   \n",
      "16                0.16090          0.3029                  0.08216   \n",
      "17                0.20730          0.3706                  0.11420   \n",
      "18                0.23880          0.2768                  0.07615   \n",
      "19                0.12880          0.2977                  0.07259   \n",
      "20                0.07283          0.3184                  0.08183   \n",
      "21                0.06227          0.2450                  0.07773   \n",
      "22                0.23930          0.4667                  0.09946   \n",
      "23                0.20090          0.2822                  0.07526   \n",
      "24                0.20950          0.3613                  0.09564   \n",
      "25                0.25500          0.4066                  0.10590   \n",
      "26                0.27010          0.4264                  0.12750   \n",
      "27                0.14900          0.2341                  0.07421   \n",
      "28                0.20240          0.4027                  0.09876   \n",
      "29                0.14560          0.2756                  0.07919   \n",
      "..                    ...             ...                      ...   \n",
      "539               0.05000          0.2790                  0.10660   \n",
      "540               0.06918          0.2329                  0.08134   \n",
      "541               0.12050          0.3187                  0.10230   \n",
      "542               0.10950          0.2722                  0.06956   \n",
      "543               0.07958          0.2473                  0.06443   \n",
      "544               0.06845          0.2249                  0.08492   \n",
      "545               0.07174          0.2642                  0.06953   \n",
      "546               0.02381          0.2681                  0.07399   \n",
      "547               0.08333          0.2691                  0.09479   \n",
      "548               0.03846          0.2552                  0.07920   \n",
      "549               0.03264          0.3059                  0.07626   \n",
      "550               0.00000          0.2458                  0.06592   \n",
      "551               0.06413          0.3169                  0.08032   \n",
      "552               0.06498          0.2407                  0.06484   \n",
      "553               0.02564          0.2435                  0.07393   \n",
      "554               0.06493          0.2372                  0.07242   \n",
      "555               0.09127          0.2226                  0.08283   \n",
      "556               0.02232          0.2262                  0.06742   \n",
      "557               0.00000          0.2475                  0.06969   \n",
      "558               0.11050          0.2258                  0.08004   \n",
      "559               0.09653          0.2112                  0.08732   \n",
      "560               0.10480          0.2250                  0.08321   \n",
      "561               0.00000          0.1566                  0.05905   \n",
      "562               0.23560          0.4089                  0.14090   \n",
      "563               0.25420          0.2929                  0.09873   \n",
      "564               0.22160          0.2060                  0.07115   \n",
      "565               0.16280          0.2572                  0.06637   \n",
      "566               0.14180          0.2218                  0.07820   \n",
      "567               0.26500          0.4087                  0.12400   \n",
      "568               0.00000          0.2871                  0.07039   \n",
      "\n",
      "     cancer type  \n",
      "0      malignant  \n",
      "1      malignant  \n",
      "2      malignant  \n",
      "3      malignant  \n",
      "4      malignant  \n",
      "5      malignant  \n",
      "6      malignant  \n",
      "7      malignant  \n",
      "8      malignant  \n",
      "9      malignant  \n",
      "10     malignant  \n",
      "11     malignant  \n",
      "12     malignant  \n",
      "13     malignant  \n",
      "14     malignant  \n",
      "15     malignant  \n",
      "16     malignant  \n",
      "17     malignant  \n",
      "18     malignant  \n",
      "19        benign  \n",
      "20        benign  \n",
      "21        benign  \n",
      "22     malignant  \n",
      "23     malignant  \n",
      "24     malignant  \n",
      "25     malignant  \n",
      "26     malignant  \n",
      "27     malignant  \n",
      "28     malignant  \n",
      "29     malignant  \n",
      "..           ...  \n",
      "539       benign  \n",
      "540       benign  \n",
      "541       benign  \n",
      "542       benign  \n",
      "543       benign  \n",
      "544       benign  \n",
      "545       benign  \n",
      "546       benign  \n",
      "547       benign  \n",
      "548       benign  \n",
      "549       benign  \n",
      "550       benign  \n",
      "551       benign  \n",
      "552       benign  \n",
      "553       benign  \n",
      "554       benign  \n",
      "555       benign  \n",
      "556       benign  \n",
      "557       benign  \n",
      "558       benign  \n",
      "559       benign  \n",
      "560       benign  \n",
      "561       benign  \n",
      "562    malignant  \n",
      "563    malignant  \n",
      "564    malignant  \n",
      "565    malignant  \n",
      "566    malignant  \n",
      "567    malignant  \n",
      "568       benign  \n",
      "\n",
      "[569 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "cancers = ds.load_breast_cancer()\n",
    "data_ = (list(i)+[cancers['target_names'][j]] for i,j in zip(cancers['data'],cancers['target']))\n",
    "cancers_pd = pd.DataFrame(data_, columns=list(cancers['feature_names'])+['cancer type'])\n",
    "\n",
    "print(cancers_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "data, target, target_names = cancers['data'], cancers['target'], cancers['target_names']\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size = 0.3, random_state=7)\n",
    "kflod = StratifiedKFold(n_splits=10, random_state=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decesion Tree\n",
      "0.9371859296482412 DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=8, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best') {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 3}\n",
      "Accuracy: 0.9415204678362573\n",
      "[[ 50   5]\n",
      " [  5 111]]\n",
      "TP:111, FP:5, FN:5, TN:50, Precesion:0.956897, Recall:0.956897\n",
      "F1_score: 0.9568965517241379\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Decesion Tree\"\"\"\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "max_depth = [10, 15, 20, 30, None]\n",
    "min_samples_split = [2, 3, 5, 8, 10]\n",
    "min_samples_leaf = [1, 2, 3, 5, 8]\n",
    "param_grid = [{'criterion': criterion, 'max_depth':max_depth, 'min_samples_split':min_samples_split, 'min_samples_leaf':min_samples_leaf}]\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, scoring=\"accuracy\", cv=kflod)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Decesion Tree\")\n",
    "print(grid_search.best_score_, grid_search.best_estimator_, grid_search.best_params_)\n",
    "print(\"Accuracy:\", best_model.score(X_test, Y_test))\n",
    "print(confusion_matrix(Y_test, best_model.predict(X_test)))\n",
    "\n",
    "TP = np.logical_and(best_model.predict(X_test)==1, Y_test==1).sum()\n",
    "FP = np.logical_and(best_model.predict(X_test)==1, Y_test==0).sum()\n",
    "FN = np.logical_and(best_model.predict(X_test)==0, Y_test==1).sum()\n",
    "TN = np.logical_and(best_model.predict(X_test)==0, Y_test==0).sum()\n",
    "print(\"TP:%d, FP:%d, FN:%d, TN:%d, Precesion:%f, Recall:%f\" %(TP, FP, FN, TN, TP/(TP+FP), TP/(TP+FN)))\n",
    "\n",
    "f1_score_value = f1_score(Y_test, best_model.predict(X_test))\n",
    "print(\"F1_score:\", f1_score_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SVM\n",
      "0.9623115577889447 SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False) {'C': 1, 'kernel': 'linear'}\n",
      "Accuracy: 0.9532163742690059\n",
      "[[ 48   7]\n",
      " [  1 115]]\n",
      "TP:115, FP:7, FN:1, TN:48, Precesion:0.942623, Recall:0.991379\n",
      "F1_score: 0.9663865546218487\n"
     ]
    }
   ],
   "source": [
    "\"\"\"SVM\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC()\n",
    "\n",
    "C = [0.1, 0.5, 1, 5, 10]\n",
    "kernel = ['linear']\n",
    "param_grid = [{'C': C, 'kernel':kernel}]\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=kflod)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"\\n SVM\")\n",
    "print(grid_search.best_score_, grid_search.best_estimator_, grid_search.best_params_)\n",
    "print(\"Accuracy:\", best_model.score(X_test, Y_test))\n",
    "print(confusion_matrix(Y_test, best_model.predict(X_test)))\n",
    "\n",
    "TP = np.logical_and(best_model.predict(X_test)==1, Y_test==1).sum()\n",
    "FP = np.logical_and(best_model.predict(X_test)==1, Y_test==0).sum()\n",
    "FN = np.logical_and(best_model.predict(X_test)==0, Y_test==1).sum()\n",
    "TN = np.logical_and(best_model.predict(X_test)==0, Y_test==0).sum()\n",
    "print(\"TP:%d, FP:%d, FN:%d, TN:%d, Precesion:%f, Recall:%f\" %(TP, FP, FN, TN, TP/(TP+FP), TP/(TP+FN)))\n",
    "\n",
    "f1_score_value = f1_score(Y_test, best_model.predict(X_test))\n",
    "print(\"F1_score:\", f1_score_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " MultinomialNB\n",
      "Accuracy: 0.9064327485380117\n",
      "[[ 40  15]\n",
      " [  1 115]]\n",
      "TP:115, FP:15, FN:1, TN:40, Precesion:0.884615, Recall:0.991379\n",
      "F1_score: 0.9349593495934959\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Bayes\"\"\"\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=0.01)\n",
    "\n",
    "clf.fit(X_train,Y_train)\n",
    "print(\"\\n MultinomialNB\")\n",
    "print(\"Accuracy:\", clf.score(X_test,Y_test))\n",
    "print(confusion_matrix(Y_test, clf.predict(X_test)))\n",
    "\n",
    "TP = np.logical_and(clf.predict(X_test)==1, Y_test==1).sum()\n",
    "FP = np.logical_and(clf.predict(X_test)==1, Y_test==0).sum()\n",
    "FN = np.logical_and(clf.predict(X_test)==0, Y_test==1).sum()\n",
    "TN = np.logical_and(clf.predict(X_test)==0, Y_test==0).sum()\n",
    "print(\"TP:%d, FP:%d, FN:%d, TN:%d, Precesion:%f, Recall:%f\" %(TP, FP, FN, TN, TP/(TP+FP), TP/(TP+FN)))\n",
    "\n",
    "f1_score_value = f1_score(Y_test, clf.predict(X_test))\n",
    "print(\"F1_score:\", f1_score_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " KNN\n",
      "0.9346733668341709 KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='distance') {'n_neighbors': 10, 'weights': 'distance'}\n",
      "Accuracy: 0.9532163742690059\n",
      "[[ 50   5]\n",
      " [  3 113]]\n",
      "TP:113, FP:5, FN:3, TN:50, Precesion:0.957627, Recall:0.974138\n",
      "F1_score: 0.9658119658119658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "\n",
    "n_neighbors = [1,2,3,5,8,10,15,20,25,30,35,40]\n",
    "weights = ['uniform','distance']\n",
    "param_grid = [{'n_neighbors': n_neighbors, 'weights': weights}]\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=kflod)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"\\n KNN\")\n",
    "print(grid_search.best_score_, grid_search.best_estimator_, grid_search.best_params_)\n",
    "print(\"Accuracy:\", best_model.score(X_test, Y_test))\n",
    "print(confusion_matrix(Y_test, best_model.predict(X_test)))\n",
    "\n",
    "TP = np.logical_and(best_model.predict(X_test)==1, Y_test==1).sum()\n",
    "FP = np.logical_and(best_model.predict(X_test)==1, Y_test==0).sum()\n",
    "FN = np.logical_and(best_model.predict(X_test)==0, Y_test==1).sum()\n",
    "TN = np.logical_and(best_model.predict(X_test)==0, Y_test==0).sum()\n",
    "print(\"TP:%d, FP:%d, FN:%d, TN:%d, Precesion:%f, Recall:%f\" %(TP, FP, FN, TN, TP/(TP+FP), TP/(TP+FN)))\n",
    "\n",
    "f1_score_value = f1_score(Y_test, best_model.predict(X_test))\n",
    "print(\"F1_score:\", f1_score_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GaussianNB\n",
      "Accuracy: 0.9532163742690059\n",
      "[[ 49   6]\n",
      " [  2 114]]\n",
      "TP:114, FP:6, FN:2, TN:49, Precesion:0.950000, Recall:0.982759\n",
      "F1_score: 0.9661016949152542\n"
     ]
    }
   ],
   "source": [
    "\"\"\"gaussian\"\"\"\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "\n",
    "clf.fit(X_train,Y_train)\n",
    "print(\"\\n GaussianNB\")\n",
    "print(\"Accuracy:\", clf.score(X_test,Y_test))\n",
    "print(confusion_matrix(Y_test, clf.predict(X_test)))\n",
    "\n",
    "TP = np.logical_and(clf.predict(X_test)==1, Y_test==1).sum()\n",
    "FP = np.logical_and(clf.predict(X_test)==1, Y_test==0).sum()\n",
    "FN = np.logical_and(clf.predict(X_test)==0, Y_test==1).sum()\n",
    "TN = np.logical_and(clf.predict(X_test)==0, Y_test==0).sum()\n",
    "print(\"TP:%d, FP:%d, FN:%d, TN:%d, Precesion:%f, Recall:%f\" %(TP, FP, FN, TN, TP/(TP+FP), TP/(TP+FN)))\n",
    "\n",
    "f1_score_value = f1_score(Y_test, clf.predict(X_test))\n",
    "print(\"F1_score:\", f1_score_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForest\n",
      "0.9547738693467337 RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False) {'n_estimators': 50}\n",
      "Accuracy: 0.9590643274853801\n",
      "[[ 50   5]\n",
      " [  2 114]]\n",
      "TP:114, FP:5, FN:2, TN:50, Precesion:0.957983, Recall:0.982759\n",
      "F1_score: 0.9702127659574468\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Forest\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "n_estimators = [10, 20, 35, 50, 80, 100, 120, 150, 200]\n",
    "param_grid = [{'n_estimators': n_estimators}]\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=kflod)\n",
    "grid_search.fit(X_train, Y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"\\nRandomForest\")\n",
    "print(grid_search.best_score_, grid_search.best_estimator_, grid_search.best_params_)\n",
    "print(\"Accuracy:\", best_model.score(X_test, Y_test))\n",
    "print(confusion_matrix(Y_test, best_model.predict(X_test)))\n",
    "\n",
    "TP = np.logical_and(best_model.predict(X_test)==1, Y_test==1).sum()\n",
    "FP = np.logical_and(best_model.predict(X_test)==1, Y_test==0).sum()\n",
    "FN = np.logical_and(best_model.predict(X_test)==0, Y_test==1).sum()\n",
    "TN = np.logical_and(best_model.predict(X_test)==0, Y_test==0).sum()\n",
    "print(\"TP:%d, FP:%d, FN:%d, TN:%d, Precesion:%f, Recall:%f\" %(TP, FP, FN, TN, TP/(TP+FP), TP/(TP+FN)))\n",
    "\n",
    "f1_score_value = f1_score(Y_test, best_model.predict(X_test))\n",
    "print(\"F1_score:\", f1_score_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGboost\n",
      "Accuracy: 0.9766081871345029\n",
      "[[ 51   4]\n",
      " [  0 116]]\n",
      "TP:116, FP:4, FN:0, TN:51, Precesion:0.966667, Recall:1.000000\n",
      "F1_score: 0.983050847457627\n"
     ]
    }
   ],
   "source": [
    "\"\"\"XGboost\"\"\"\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train,Y_train)\n",
    "print(\"\\nXGboost\")\n",
    "print(\"Accuracy:\", clf.score(X_test,Y_test))\n",
    "print(confusion_matrix(Y_test, clf.predict(X_test)))\n",
    "\n",
    "TP = np.logical_and(clf.predict(X_test)==1, Y_test==1).sum()\n",
    "FP = np.logical_and(clf.predict(X_test)==1, Y_test==0).sum()\n",
    "FN = np.logical_and(clf.predict(X_test)==0, Y_test==1).sum()\n",
    "TN = np.logical_and(clf.predict(X_test)==0, Y_test==0).sum()\n",
    "print(\"TP:%d, FP:%d, FN:%d, TN:%d, Precesion:%f, Recall:%f\" %(TP, FP, FN, TN, TP/(TP+FP), TP/(TP+FN)))\n",
    "\n",
    "f1_score_value = f1_score(Y_test, clf.predict(X_test))\n",
    "print(\"F1_score:\", f1_score_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
